{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS0tTDitdn6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe35433-99c3-47ea-a348-d11820294529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3108, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2901, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 441, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 572, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 216, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2821, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3110, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3120, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3173, in __init__\n",
            "    super(Requirement, self).__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 102, in __init__\n",
            "    req = REQUIREMENT.parseString(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 1131, in parse_string\n",
            "    loc, tokens = self._parse(instring, 0)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3864, in parseImpl\n",
            "    loc, resultlist = self.exprs[0]._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4959, in parseImpl\n",
            "    loc, tokens = self_expr._parse(instring, loc, doActions, callPreParse=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 4114, in parseImpl\n",
            "    return e._parse(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 817, in _parseNoCache\n",
            "    loc, tokens = self.parseImpl(instring, pre_loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 3886, in parseImpl\n",
            "    loc, exprtokens = e._parse(instring, loc, doActions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/core.py\", line 825, in _parseNoCache\n",
            "    ret_tokens = ParseResults(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyparsing/results.py\", line 159, in __init__\n",
            "    def __init__(\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1724, in isEnabledFor\n",
            "    def isEnabledFor(self, level):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n",
        "!pip install wandb\n",
        "!pip install codecarbon\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIhtPXtyHwDo",
        "outputId": "3aa17862-86d0-409e-f6ae-2bb9df9331d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login 6d0d4fcf28a32488eb9c49d8fb9198328577975c"
      ],
      "metadata": {
        "id": "14MiuSXQ-_qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6616563-6066-4bce-ec52-0c3fb127097d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8MM7SlecTuv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "#list the current working dir\n",
        "os.getcwd()\n",
        "#change the current working dir\n",
        "os.chdir('/content/drive/MyDrive/HPVIT')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm, trange\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.datasets.cifar import CIFAR10, CIFAR100\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "from torchvision.datasets import VOCSegmentation\n",
        "import wandb\n",
        "from codecarbon import track_emissions\n",
        "# VISION TRANSFORMER PROBABILISTICO CON FEATURE SELECTION\n",
        "# from hvit.heuristic_vision_transformer_block import HViT\n",
        "# VISION TRANSFORMER CON FEATURE SELECTION\n",
        "from hvit.filtered_vision_transformer_block import FViT\n",
        "# VISION TRANSFORMER \n",
        "from hvit.vision_transformer_block import ViT"
      ],
      "metadata": {
        "id": "Zy9OWmoPH-fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 Dataset Loader"
      ],
      "metadata": {
        "id": "OFmh_dypox-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        # Resize the image to (64, 64)\n",
        "        transforms.Resize((224, 224)),\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the image with mean and standard deviation of 0.5\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "# Load CIFAR10 dataset\n",
        "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, shuffle=False, batch_size=128)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4qjfmzjICPn",
        "outputId": "78212262-8667-4b77-955b-cfdab7829367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR100 Dataset Loader"
      ],
      "metadata": {
        "id": "De8SDcAho0OT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        # Resize the image to (64, 64)\n",
        "        transforms.Resize((224, 224)),\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the image with mean and standard deviation of 0.5\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "# Load CIFAR10 dataset\n",
        "train_set = CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, shuffle=False, batch_size=128)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxQqppG3o5BG",
        "outputId": "71296438-db6d-4ab2-c493-f20e47288518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Dataset Loader"
      ],
      "metadata": {
        "id": "k1zGhhKbpnAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        # Resize the image to (64, 64)\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.Resize((224, 224)),\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the image with mean and standard deviation of 0.5\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "# Load CIFAR10 dataset\n",
        "train_set = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, shuffle=False, batch_size=128)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)"
      ],
      "metadata": {
        "id": "G_rPDp7BqDUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VOCSegmentation DATASET LOADER"
      ],
      "metadata": {
        "id": "eVUi4J453KWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        # Resize the image to (64, 64)\n",
        "        transforms.Resize((224, 224)),\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the image with mean and standard deviation of 0.5\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "# Load CIFAR10 dataset\n",
        "train_set = VOCSegmentation(root='./data',year='2012',image_set='train', download=True, transform=transform)\n",
        "test_set = VOCSegmentation(root='./data',year='2012',image_set='trainval', download=True, transform=transform)\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, shuffle=False, batch_size=128)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtQ5UJ0-3OIT",
        "outputId": "86c8de04-84f8-425e-b3ca-04904e0e2ce7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n",
            "Using downloaded and verified file: ./data/VOCtrainval_11-May-2012.tar\n",
            "Extracting ./data/VOCtrainval_11-May-2012.tar to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define device"
      ],
      "metadata": {
        "id": "jOC-fUnurR0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print('Using GPU')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print('GPU is not available, using CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u67jWPn0IDyR",
        "outputId": "34c08e66-5e6e-400c-a2eb-0276e4a81794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run"
      ],
      "metadata": {
        "id": "Yo4L68_QK3Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "depths = 2\n",
        "project_name = f\"RQ2_Depths_{depths}_train\"\n",
        "run = \"default\"\n",
        "dataset = \"VOCSegmentation\"\n",
        "classes = 19"
      ],
      "metadata": {
        "id": "7VNEUbefIFCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "AIPHtPp-Kp8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "3hqcCvOq8a_q",
        "outputId": "71ffed5b-1a0c-4957-f320-3b87b074fd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">default</strong> at: <a href='https://wandb.ai/mali_team/RQ2_Depths_2_train/runs/rzx4nf62' target=\"_blank\">https://wandb.ai/mali_team/RQ2_Depths_2_train/runs/rzx4nf62</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230521_201229-rzx4nf62/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Goq8gcilWJla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "0e127eef-bc9c-4f1c-b7cd-2993fcab87ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma_li\u001b[0m (\u001b[33mmali_team\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/HPVIT/wandb/run-20230521_201229-rzx4nf62</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mali_team/RQ2_Depths_2_train/runs/rzx4nf62' target=\"_blank\">default</a></strong> to <a href='https://wandb.ai/mali_team/RQ2_Depths_2_train' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mali_team/RQ2_Depths_2_train' target=\"_blank\">https://wandb.ai/mali_team/RQ2_Depths_2_train</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mali_team/RQ2_Depths_2_train/runs/rzx4nf62' target=\"_blank\">https://wandb.ai/mali_team/RQ2_Depths_2_train/runs/rzx4nf62</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 20:12:30] offline tracker init\n",
            "[codecarbon INFO @ 20:12:30] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 20:12:30] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 20:12:30] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 20:12:30] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 20:12:30] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 20:12:32] We saw that you have a Intel(R) Xeon(R) CPU @ 2.30GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 20:12:32] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "[codecarbon INFO @ 20:12:32] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 20:12:32]   Platform system: Linux-5.15.107+-x86_64-with-glibc2.31\n",
            "[codecarbon INFO @ 20:12:32]   Python version: 3.10.11\n",
            "[codecarbon INFO @ 20:12:32]   CodeCarbon version: 2.2.1\n",
            "[codecarbon INFO @ 20:12:32]   Available RAM : 12.678 GB\n",
            "[codecarbon INFO @ 20:12:32]   CPU count: 2\n",
            "[codecarbon INFO @ 20:12:32]   CPU model: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "[codecarbon INFO @ 20:12:32]   GPU count: 1\n",
            "[codecarbon INFO @ 20:12:32]   GPU model: 1 x Tesla T4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (Tesla T4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/5 [00:02<?, ?it/s]\n",
            "[codecarbon INFO @ 20:12:39] \n",
            "Graceful stopping: collecting and writing information.\n",
            "Please wait a few seconds...\n",
            "[codecarbon INFO @ 20:12:39] Energy consumed for RAM : 0.000009 kWh. RAM Power : 4.754399299621582 W\n",
            "[codecarbon INFO @ 20:12:39] Energy consumed for all GPUs : 0.000051 kWh. Total GPU Power : 25.669 W\n",
            "[codecarbon INFO @ 20:12:39] Energy consumed for all CPUs : 0.000085 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 20:12:39] 0.000146 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 20:12:39] Done!\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-263f0b044ac4>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/codecarbon/emissions_tracker.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    838\u001b[0m             \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m                 \u001b[0mfn_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m                 logger.info(\n",
            "\u001b[0;32m<ipython-input-15-263f0b044ac4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>"
          ]
        }
      ],
      "source": [
        "if run != 'default':\n",
        "  wandb.init(\n",
        "  # set the wandb project where this run will be logged\n",
        "  project=project_name,\n",
        "  name=run,\n",
        "  # track hyperparameters and run metadata\n",
        "  config={\n",
        "        \"FViT\": True,\n",
        "        \"dataset\": dataset,\n",
        "        \"task\": \"Image Recognition\",\n",
        "        \"epochs\": 5,\n",
        "        \"learning_rate\":1e-3,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"loss\": \"Cross Entropy\",\n",
        "        \"in_channels\":3,\n",
        "        \"patch_size\":16,\n",
        "        \"emb_size\":64,\n",
        "        \"img_size\":224,\n",
        "        \"depth\":depths,\n",
        "        \"num_heads\":12,\n",
        "        \"n_classes\":classes,\n",
        "        \"top_k\":138,\n",
        "        \"heuristic\": run,\n",
        "        \"probabilistic\":True,\n",
        "        \"prob\":0.5,\n",
        "        \"decay_rate\":5e-3,\n",
        "        \"batch_size\":len(train_loader),\n",
        "      }\n",
        "  )\n",
        "else:\n",
        "  wandb.init(\n",
        "      # set the wandb project where this run will be logged\n",
        "      project=project_name,\n",
        "      name=run,\n",
        "      # track hyperparameters and run metadata\n",
        "      config={\n",
        "        \"FViT\": False,\n",
        "        \"dataset\": dataset,\n",
        "        \"task\": \"Image Recognition\",\n",
        "        \"epochs\": 5,\n",
        "        \"learning_rate\":1e-3,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"loss\": \"Cross Entropy\",\n",
        "        \"in_channels\":3,\n",
        "        \"patch_size\":16,\n",
        "        \"emb_size\":64,\n",
        "        \"img_size\":224,\n",
        "        \"depth\":depths,\n",
        "        \"num_heads\":12,\n",
        "        \"n_classes\":classes,\n",
        "        \"batch_size\":len(train_loader),\n",
        "      }\n",
        "  )\n",
        "\n",
        "@track_emissions(offline=True, country_iso_code=\"ITA\", output_file=f\"./evaluation/{project_name}_{run}_{dataset}.csv\")\n",
        "def train():\n",
        "    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
        "    # Defining model and training parameters\n",
        "    '''\n",
        "    model = HViT(in_channels=3,\n",
        "                 patch_size=16,\n",
        "                 emb_size=64,\n",
        "                 img_size=224,\n",
        "                 depth=8,\n",
        "                 num_heads=12,\n",
        "                 n_classes=10,\n",
        "                 top_k=128,\n",
        "                 heuristic='contrast',\n",
        "                 prob=0,\n",
        "                 decay_rate=0,\n",
        "                 probabilistic=True,\n",
        "                 batch_size=len(train_loader),\n",
        "                 verbose=False).to(device)\n",
        "    '''\n",
        "    if run == 'default':\n",
        "      model = ViT(in_channels=3,\n",
        "                patch_size=16,\n",
        "                emb_size=64,\n",
        "                img_size=224,\n",
        "                depth=depths,\n",
        "                n_classes=classes,\n",
        "                num_heads=12).to(device)\n",
        "    else:\n",
        "      model = FViT(in_channels=3,\n",
        "                 patch_size=16,\n",
        "                 emb_size=64,\n",
        "                 img_size=224,\n",
        "                 depth=depths,\n",
        "                 num_heads=12,\n",
        "                 n_classes=classes,\n",
        "                 top_k=138,\n",
        "                 heuristic=run,\n",
        "                 probabilistic=True,\n",
        "                 prob=0.5,\n",
        "                 decay_rate=5e-3,\n",
        "                 batch_size=len(train_loader),\n",
        "                 verbose=False).to(device)\n",
        "       \n",
        "    \n",
        "    \n",
        "    n_epochs = 5\n",
        "    lr = 1e-3\n",
        "    # Training loop\n",
        "    optimizer = Adam(model.parameters(), lr=lr)\n",
        "    criterion = CrossEntropyLoss()\n",
        "    \n",
        "    for epoch in trange(n_epochs, desc=\"Training\"):\n",
        "      train_loss = 0.0\n",
        "      for batch in train_loader:\n",
        "        x, y = batch\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_hat = model(x)\n",
        "        loss = criterion(y_hat, y)\n",
        "        train_loss += loss.detach().cpu().item() / len(train_loader)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      \n",
        "      print(f\"Epoch {epoch + 1}/{n_epochs} loss: {train_loss:.2f}\")\n",
        "      wandb.log({'loss': train_loss})\n",
        "    return model;\n",
        "\n",
        "model = train()\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = f\"RQ2_Depths_{depths}_inference\"\n",
        "\n",
        "if run != 'default':\n",
        "  wandb.init(\n",
        "  # set the wandb project where this run will be logged\n",
        "  project=project_name,\n",
        "  name=run,\n",
        "  # track hyperparameters and run metadata\n",
        "  config={\n",
        "        \"FViT\": True,\n",
        "        \"dataset\": dataset,\n",
        "        \"task\": \"Image Recognition\",\n",
        "        \"epochs\": 5,\n",
        "        \"learning_rate\":1e-3,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"loss\": \"Cross Entropy\",\n",
        "        \"in_channels\":3,\n",
        "        \"patch_size\":16,\n",
        "        \"emb_size\":64,\n",
        "        \"img_size\":224,\n",
        "        \"depth\":depths,\n",
        "        \"num_heads\":12,\n",
        "        \"n_classes\":classes,\n",
        "        \"top_k\":138,\n",
        "        \"heuristic\": run,\n",
        "        \"probabilistic\":True,\n",
        "        \"prob\":0.5,\n",
        "        \"decay_rate\":5e-3,\n",
        "        \"batch_size\":len(train_loader),\n",
        "      }\n",
        "  )\n",
        "else:\n",
        "  wandb.init(\n",
        "      # set the wandb project where this run will be logged\n",
        "      project=project_name,\n",
        "      name=run,\n",
        "      # track hyperparameters and run metadata\n",
        "      config={\n",
        "        \"FViT\": False,\n",
        "        \"dataset\": dataset,\n",
        "        \"task\": \"Image Recognition\",\n",
        "        \"epochs\": 5,\n",
        "        \"learning_rate\":1e-3,\n",
        "        \"optimizer\": \"Adam\",\n",
        "        \"loss\": \"Cross Entropy\",\n",
        "        \"in_channels\":3,\n",
        "        \"patch_size\":16,\n",
        "        \"emb_size\":64,\n",
        "        \"img_size\":224,\n",
        "        \"depth\":depths,\n",
        "        \"num_heads\":12,\n",
        "        \"n_classes\":classes,\n",
        "        \"batch_size\":len(train_loader),\n",
        "      }\n",
        "  )\n",
        "\n",
        "@track_emissions(offline=True, country_iso_code=\"ITA\", output_file=f\"./evaluation/{project_name}_{run}_{dataset}.csv\")\n",
        "def inference():\n",
        "  criterion = CrossEntropyLoss()\n",
        "  with torch.no_grad():\n",
        "      correct, total = 0, 0\n",
        "      test_loss = 0.0\n",
        "      for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "          x, y = batch\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          y_hat = model(x)\n",
        "          loss = criterion(y_hat, y)\n",
        "          test_loss += loss.detach().cpu().item() / len(test_loader)\n",
        "\n",
        "          correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
        "          total += len(x)\n",
        "      print(f\"Test loss: {test_loss:.2f}\")\n",
        "      wandb.log({'loss': test_loss})\n",
        "      print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
        "      accuracy = correct / total * 100\n",
        "      wandb.log({'accuracy': accuracy})\n",
        "\n",
        "inference()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "EPoC4wNTJCFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ec54390a226b4509b3ca3c8860c2e122",
            "4a038eda02674d429e9bf8d59343a906",
            "09be429a697240a494b974f5c8f93365",
            "179491c3da074f0d88e6bc5b96ad1573",
            "128de0695f054961b6ad82c6d84d5745",
            "44061c6ea18543329a67628f1333ecfe",
            "9fdd31ee489d45de9af521fb52767c64",
            "d3bc17fb22ef4cedb1b144af437ef895"
          ]
        },
        "outputId": "a3b05539-ca46-4c08-c7b8-2e5bafd67416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/HPVIT/wandb/run-20230519_143259-z9g4926k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mali_team/RQ2_Depths_8_inference/runs/z9g4926k' target=\"_blank\">default</a></strong> to <a href='https://wandb.ai/mali_team/RQ2_Depths_8_inference' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mali_team/RQ2_Depths_8_inference' target=\"_blank\">https://wandb.ai/mali_team/RQ2_Depths_8_inference</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mali_team/RQ2_Depths_8_inference/runs/z9g4926k' target=\"_blank\">https://wandb.ai/mali_team/RQ2_Depths_8_inference/runs/z9g4926k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:33:01] offline tracker init\n",
            "[codecarbon INFO @ 14:33:01] [setup] RAM Tracking...\n",
            "[codecarbon INFO @ 14:33:01] [setup] GPU Tracking...\n",
            "[codecarbon INFO @ 14:33:01] Tracking Nvidia GPU via pynvml\n",
            "[codecarbon INFO @ 14:33:01] [setup] CPU Tracking...\n",
            "[codecarbon WARNING @ 14:33:01] No CPU tracking mode found. Falling back on CPU constant mode.\n",
            "[codecarbon WARNING @ 14:33:02] We saw that you have a Intel(R) Xeon(R) CPU @ 2.20GHz but we don't know it. Please contact us.\n",
            "[codecarbon INFO @ 14:33:02] CPU Model on constant consumption mode: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 14:33:03] >>> Tracker's metadata:\n",
            "[codecarbon INFO @ 14:33:03]   Platform system: Linux-5.15.107+-x86_64-with-glibc2.31\n",
            "[codecarbon INFO @ 14:33:03]   Python version: 3.10.11\n",
            "[codecarbon INFO @ 14:33:03]   CodeCarbon version: 2.2.1\n",
            "[codecarbon INFO @ 14:33:03]   Available RAM : 12.678 GB\n",
            "[codecarbon INFO @ 14:33:03]   CPU count: 2\n",
            "[codecarbon INFO @ 14:33:03]   CPU model: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "[codecarbon INFO @ 14:33:03]   GPU count: 1\n",
            "[codecarbon INFO @ 14:33:03]   GPU model: 1 x Tesla T4\n",
            "Testing:  44%|████▍     | 35/79 [00:14<00:17,  2.57it/s][codecarbon INFO @ 14:33:18] Energy consumed for RAM : 0.000020 kWh. RAM Power : 4.754399299621582 W\n",
            "[codecarbon INFO @ 14:33:18] Energy consumed for all GPUs : 0.000456 kWh. Total GPU Power : 109.299 W\n",
            "[codecarbon INFO @ 14:33:18] Energy consumed for all CPUs : 0.000177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:18] 0.000653 kWh of electricity used since the beginning.\n",
            "Testing:  90%|████████▉ | 71/79 [00:29<00:03,  2.57it/s][codecarbon INFO @ 14:33:33] Energy consumed for RAM : 0.000040 kWh. RAM Power : 4.754399299621582 W\n",
            "[codecarbon INFO @ 14:33:33] Energy consumed for all GPUs : 0.000751 kWh. Total GPU Power : 70.781 W\n",
            "[codecarbon INFO @ 14:33:33] Energy consumed for all CPUs : 0.000355 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:33] 0.001145 kWh of electricity used since the beginning.\n",
            "Testing: 100%|██████████| 79/79 [00:32<00:00,  2.41it/s]\n",
            "[codecarbon INFO @ 14:33:35] \n",
            "Graceful stopping: collecting and writing information.\n",
            "Please wait a few seconds...\n",
            "[codecarbon INFO @ 14:33:35] Energy consumed for RAM : 0.000043 kWh. RAM Power : 4.754399299621582 W\n",
            "[codecarbon INFO @ 14:33:35] Energy consumed for all GPUs : 0.000805 kWh. Total GPU Power : 70.303 W\n",
            "[codecarbon INFO @ 14:33:35] Energy consumed for all CPUs : 0.000388 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:35] 0.001237 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 14:33:35] Done!\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.09\n",
            "Test accuracy: 97.39%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec54390a226b4509b3ca3c8860c2e122"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>97.39</td></tr><tr><td>loss</td><td>0.08975</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">default</strong> at: <a href='https://wandb.ai/mali_team/RQ2_Depths_8_inference/runs/z9g4926k' target=\"_blank\">https://wandb.ai/mali_team/RQ2_Depths_8_inference/runs/z9g4926k</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230519_143259-z9g4926k/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec54390a226b4509b3ca3c8860c2e122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a038eda02674d429e9bf8d59343a906",
              "IPY_MODEL_09be429a697240a494b974f5c8f93365"
            ],
            "layout": "IPY_MODEL_179491c3da074f0d88e6bc5b96ad1573"
          }
        },
        "4a038eda02674d429e9bf8d59343a906": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_128de0695f054961b6ad82c6d84d5745",
            "placeholder": "​",
            "style": "IPY_MODEL_44061c6ea18543329a67628f1333ecfe",
            "value": "0.001 MB of 0.012 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "09be429a697240a494b974f5c8f93365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9fdd31ee489d45de9af521fb52767c64",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3bc17fb22ef4cedb1b144af437ef895",
            "value": 0.09183037106329903
          }
        },
        "179491c3da074f0d88e6bc5b96ad1573": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "128de0695f054961b6ad82c6d84d5745": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44061c6ea18543329a67628f1333ecfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9fdd31ee489d45de9af521fb52767c64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3bc17fb22ef4cedb1b144af437ef895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
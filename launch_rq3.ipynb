{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install wandb\n",
        "!pip install codecarbon\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "hgx-3KIZbMiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miH98MMIb8P0",
        "outputId": "2fad08cd-545b-461b-ed7b-61e00daf2361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "#list the current working dir\n",
        "os.getcwd()\n",
        "#change the current working dir\n",
        "os.chdir('/content/drive/MyDrive/HPVIT')"
      ],
      "metadata": {
        "id": "TWlSSiMucGBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets.cifar import CIFAR10, CIFAR100\n",
        "from torch.optim import Adam\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import wandb\n",
        "from codecarbon import track_emissions\n",
        "# VISION TRANSFORMER PROBABILISTICO CON FEATURE SELECTION\n",
        "# from hvit.heuristic_vision_transformer_block import HViT\n",
        "# VISION TRANSFORMER CON FEATURE SELECTION\n",
        "from hvit.heuristic_vision_transformer_block import HViT\n",
        "# VISION TRANSFORMER \n",
        "from hvit.vision_transformer_block import ViT"
      ],
      "metadata": {
        "id": "o3WqxVcS85Gf",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:32:36.261331Z",
          "end_time": "2023-05-22T01:32:38.846072Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Contrastive Learning Loss"
      ],
      "metadata": {
        "id": "Gwwc1jtAbuOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, embeddings, labels):\n",
        "        batch_size = embeddings.size(0)\n",
        "        pairwise_distances = torch.cdist(embeddings, embeddings)\n",
        "        positive_distances = pairwise_distances[labels == 1]\n",
        "        negative_distances = pairwise_distances[labels == 0]\n",
        "        hard_negative_distances, _ = negative_distances.max(dim=1)\n",
        "\n",
        "        loss = (positive_distances.pow(2).sum() +\n",
        "                torch.clamp(self.margin - hard_negative_distances.pow(2), min=0).sum()) / batch_size\n",
        "        return loss"
      ],
      "metadata": {
        "id": "Pn9cypT783uK",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:02:43.152224Z",
          "end_time": "2023-05-22T01:02:43.171186Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting Device\n"
      ],
      "metadata": {
        "id": "scgt4F8GczDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    map_location=lambda storage, loc: storage.cuda()\n",
        "    print('Using GPU')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    map_location='cpu'\n",
        "    print('GPU is not available, using CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R5hnVCl9IHE",
        "outputId": "d9a77749-c79f-41d5-83c8-ab1bbb91768e",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:32:54.268123Z",
          "end_time": "2023-05-22T01:32:54.799216Z"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR10 Dataset Loader"
      ],
      "metadata": {
        "id": "fOZaASQOc1La"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "        # Resize the image to (64, 64)\n",
        "        transforms.Resize((224, 224)),\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "        # Normalize the image with mean and standard deviation of 0.5\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "# Load CIFAR10 dataset\n",
        "train_set = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_set, shuffle=False, batch_size=128)\n",
        "test_loader = DataLoader(test_set, shuffle=False, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVmA-nWj9NQH",
        "outputId": "d8531189-6907-41e4-c8fa-2918005d1840",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:04:57.867811Z",
          "end_time": "2023-05-22T01:04:59.273643Z"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PRETRAINING"
      ],
      "metadata": {
        "id": "DcxuELSXNVQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wand login 6d0d4fcf28a32488eb9c49d8fb9198328577975c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RYUjk-Vptad",
        "outputId": "a3ccbb5c-2fd2-4480-bd90-08c89b4061c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: wand: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = 'heuristic'\n",
        "training = 'type_1'\n",
        "output_dim = 128\n",
        "depths = 2\n",
        "project_name = f\"RQ3\"\n",
        "dataset = \"VOCSegmentation\"\n",
        "classes = 10\n",
        "pre_training = True\n",
        "contrastive_learning = False\n",
        "fine_tuning = True"
      ],
      "metadata": {
        "id": "tMEuYgYEdDB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if run != 'default':\n",
        "  wandb.init(\n",
        "  # set the wandb project where this run will be logged\n",
        "  project=project_name,\n",
        "  name=f'{run}_{training}',\n",
        "  # track hyperparameters and run metadata\n",
        "  config={\n",
        "        \"FViT\": True,\n",
        "        \"pre-training\": pre_training,\n",
        "        \"contrastive learning\": contrastive_learning,\n",
        "        \"fine-tuning\": fine_tuning,\n",
        "        \"task\": \"Image Recognition\",\n",
        "        \"num_heads\":12,\n",
        "      }\n",
        "  )\n",
        "else:\n",
        "  wandb.init(\n",
        "      # set the wandb project where this run will be logged\n",
        "      project=project_name,\n",
        "      name=f'{run}_{training}',\n",
        "      # track hyperparameters and run metadata\n",
        "      config={\n",
        "        \"FViT\": False,\n",
        "        \"pre-training\": pre_training,\n",
        "        \"contrastive learning\": contrastive_learning,\n",
        "        \"fine-tuning\": fine_tuning,\n",
        "        \"task\": \"Image Recognition\",\n",
        "        \"num_heads\":12,\n",
        "      }\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "B7Ttd0wqp4ZC",
        "outputId": "9f945d1d-7bac-4585-ef07-3fd9f5208796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/HPVIT/wandb/run-20230522_105722-eyhnpgxs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mali_team/RQ3/runs/eyhnpgxs' target=\"_blank\">heuristic_type_1</a></strong> to <a href='https://wandb.ai/mali_team/RQ3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/mali_team/RQ3' target=\"_blank\">https://wandb.ai/mali_team/RQ3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/mali_team/RQ3/runs/eyhnpgxs' target=\"_blank\">https://wandb.ai/mali_team/RQ3/runs/eyhnpgxs</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run == 'default':\n",
        "      model = ViT(in_channels=3,\n",
        "                patch_size=16,\n",
        "                emb_size=64,\n",
        "                img_size=224,\n",
        "                depth=2,\n",
        "                n_classes=output_dim,\n",
        "                num_heads=12).to(device)\n",
        "else:\n",
        "      model = HViT(in_channels=3,\n",
        "                 patch_size=16,\n",
        "                 emb_size=64,\n",
        "                 img_size=224,\n",
        "                 depth=2,\n",
        "                 num_heads=12,\n",
        "                 n_classes=output_dim,\n",
        "                 top_k=138,\n",
        "                 heuristic='variance',\n",
        "                 probabilistic=False,\n",
        "                 prob=1,\n",
        "                 decay_rate=0.0,\n",
        "                 batch_size=len(train_loader),\n",
        "                 verbose=False).to(device)"
      ],
      "metadata": {
        "id": "uNFQp6lI9uCP",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:04:59.732429Z",
          "end_time": "2023-05-22T01:04:59.764113Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if contrastive_learning:\n",
        "  n_epochs = 5\n",
        "else:\n",
        "  n_epochs = 10\n",
        "\n",
        "lr = 1e-3\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "nK3Ym7dw9fhR",
        "ExecuteTime": {
          "start_time": "2023-05-22T00:54:13.685742Z",
          "end_time": "2023-05-22T00:54:13.720761Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pretraining loop\n",
        "for epoch in trange(n_epochs, desc=\"Training\"):\n",
        "  running_loss = 0.0\n",
        "  for batch in train_loader:\n",
        "    # Move images and labels to the device\n",
        "    images, labels = batch\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward pass and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "\n",
        "  print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtoXOoHm-BGe",
        "outputId": "5ed5f230-3a1b-48f6-e56f-c5769bb5aec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Epoch:  0\n",
            "Probability:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|█         | 1/10 [03:01<27:12, 181.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.8956\n",
            "\n",
            "Current Epoch:  1\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 2/10 [06:03<24:15, 181.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10], Loss: 1.5068\n",
            "\n",
            "Current Epoch:  2\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 3/10 [09:05<21:14, 182.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10], Loss: 1.3664\n",
            "\n",
            "Current Epoch:  3\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 4/10 [12:08<18:14, 182.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10], Loss: 1.2701\n",
            "\n",
            "Current Epoch:  4\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 5/10 [15:11<15:11, 182.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10], Loss: 1.1994\n",
            "\n",
            "Current Epoch:  5\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 6/10 [18:14<12:10, 182.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10], Loss: 1.1422\n",
            "\n",
            "Current Epoch:  6\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 7/10 [21:15<09:06, 182.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10], Loss: 1.0936\n",
            "\n",
            "Current Epoch:  7\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 8/10 [24:17<06:04, 182.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10], Loss: 1.0623\n",
            "\n",
            "Current Epoch:  8\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 9/10 [27:19<03:02, 182.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10], Loss: 1.0373\n",
            "\n",
            "Current Epoch:  9\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 10/10 [30:20<00:00, 182.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10], Loss: 1.0031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model_after_pretraining.pth\")"
      ],
      "metadata": {
        "id": "x44RMMwI-0k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONTRASTIVE LEARNING"
      ],
      "metadata": {
        "id": "LCYGehYbNW2q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if contrastive_learning:\n",
        "  model.load_state_dict(torch.load(\"model_after_pretraining.pth\"))\n",
        "  model.to(device)"
      ],
      "metadata": {
        "id": "-tr7fVUbNsFz",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:05:02.031189Z",
          "end_time": "2023-05-22T01:05:02.053412Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if contrastive_learning:\n",
        "  margin = 1.0\n",
        "  n_epochs = 1\n",
        "  lr = 1e-3\n",
        "  criterion = ContrastiveLoss(margin)\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "  batch_size = 128"
      ],
      "metadata": {
        "id": "IQgPntlJ-Ec7",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:07:30.455154Z",
          "end_time": "2023-05-22T01:07:30.470144Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if contrastive_learning:\n",
        "  for epoch in trange(n_epochs):\n",
        "      for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "          # Forward pass\n",
        "          if torch.cuda.is_available():\n",
        "              images = images.cuda(non_blocking=True)\n",
        "              labels = labels.cuda(non_blocking=True)\n",
        "          images = images.to(device)\n",
        "\n",
        "          labels = labels.to(device)\n",
        "          features = model(images)\n",
        "          loss = criterion(features, labels)\n",
        "\n",
        "          # Backward pass and optimization\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Print training progress\n",
        "          if (batch_idx+1) % 10 == 0:\n",
        "              print(f\"Epoch [{epoch+1}/{n_epochs}], Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "Es7sFNoj9rAY",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:07:31.113894Z",
          "end_time": "2023-05-22T01:14:32.914338Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if contrastive_learning:\n",
        "  torch.save(model.state_dict(), \"model_after_contrastive_learning.pth\")"
      ],
      "metadata": {
        "id": "YQfgfXvaJA7-",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:14:32.916320Z",
          "end_time": "2023-05-22T01:14:32.973123Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FINETUNING"
      ],
      "metadata": {
        "id": "bQTdjzuoNY1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if run == 'default':\n",
        "      pretrained_model = ViT(in_channels=3,\n",
        "                patch_size=16,\n",
        "                emb_size=64,\n",
        "                img_size=224,\n",
        "                depth=2,\n",
        "                n_classes=output_dim,\n",
        "                num_heads=12).to(device)\n",
        "else:\n",
        "      pretrained_model = HViT(in_channels=3,\n",
        "                 patch_size=16,\n",
        "                 emb_size=64,\n",
        "                 img_size=224,\n",
        "                 depth=2,\n",
        "                 num_heads=12,\n",
        "                 n_classes=output_dim,\n",
        "                 top_k=138,\n",
        "                 heuristic='variance',\n",
        "                 probabilistic=False,\n",
        "                 prob=1,\n",
        "                 decay_rate=0.0,\n",
        "                 batch_size=len(train_loader),\n",
        "                 verbose=False).to(device)\n",
        "\n",
        "if contrastive_learning:\n",
        "  pretrained_model.load_state_dict(torch.load(\"model_after_contrastive_learning.pth\"))  \n",
        "  pretrained_model.to(device)\n",
        "else:\n",
        "  pretrained_model.load_state_dict(torch.load(\"model_after_pretraining.pth\"))  \n",
        "  pretrained_model.to(device)"
      ],
      "metadata": {
        "id": "FuA8U886JHto",
        "ExecuteTime": {
          "start_time": "2023-05-22T01:33:02.462590Z",
          "end_time": "2023-05-22T01:33:03.711250Z"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(input_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "    def forward(self, x):\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "# Creating an instance of MLPClassifier\n",
        "input_size = 128\n",
        "hidden_size = 256\n",
        "num_classes = 100"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-05-22T01:33:04.549036Z",
          "end_time": "2023-05-22T01:33:04.569525Z"
        },
        "id": "EV6IpgvYbB9N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "classification_head = ClassificationHead(input_size, hidden_size, num_classes).to(device)\n",
        "\n",
        "# Combine the base model and the classification head\n",
        "model_final = nn.Sequential(pretrained_model, classification_head).to(device)"
      ],
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-05-22T01:35:05.397783Z",
          "end_time": "2023-05-22T01:35:05.446506Z"
        },
        "id": "F4kEWRLAbB9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")   \n",
        "\n",
        "\n",
        "n_epochs = 5\n",
        "lr = 1e-3\n",
        "# Training loop\n",
        "optimizer = Adam(model_final.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in trange(n_epochs, desc=\"Training\"):\n",
        "  train_loss = 0.0\n",
        "  for batch in train_loader:\n",
        "    x, y = batch\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    y_hat = model_final(x)\n",
        "    loss = criterion(y_hat, y)\n",
        "    train_loss += loss.detach().cpu().item() / len(train_loader)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  \n",
        "  print(f\"Epoch {epoch + 1}/{n_epochs} loss: {train_loss:.2f}\")"
      ],
      "metadata": {
        "id": "NDzb05_e_d6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69e7cc0-5628-48cc-d4f0-067f80619a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (Tesla T4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Epoch:  0\n",
            "Probability:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 1/5 [02:12<08:48, 132.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 loss: 4.22\n",
            "\n",
            "Current Epoch:  1\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 2/5 [04:23<06:35, 131.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 loss: 4.11\n",
            "\n",
            "Current Epoch:  2\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 3/5 [06:35<04:23, 131.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 loss: 4.08\n",
            "\n",
            "Current Epoch:  3\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 4/5 [08:46<02:11, 131.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 loss: 4.08\n",
            "\n",
            "Current Epoch:  4\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 5/5 [10:57<00:00, 131.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 loss: 4.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_final"
      ],
      "metadata": {
        "id": "vYQcPKR7qs9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inference():\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  with torch.no_grad():\n",
        "      correct, total = 0, 0\n",
        "      test_loss = 0.0\n",
        "      for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "          x, y = batch\n",
        "          x, y = x.to(device), y.to(device)\n",
        "          y_hat = model(x)\n",
        "          loss = criterion(y_hat, y)\n",
        "          test_loss += loss.detach().cpu().item() / len(test_loader)\n",
        "\n",
        "          correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
        "          total += len(x)\n",
        "      print(f\"Test loss: {test_loss:.2f}\")\n",
        "      wandb.log({'loss': test_loss})\n",
        "      print(f\"Test accuracy: {correct / total * 100:.2f}%\")\n",
        "      accuracy = correct / total * 100\n",
        "      wandb.log({'accuracy': accuracy})\n",
        "\n",
        "inference()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6IPMRukqpvp",
        "outputId": "5d81e6e4-1b3f-4df2-b9bc-5ca33d91d15b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing:   1%|▏         | 1/79 [00:00<00:23,  3.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Current Epoch:  5\n",
            "Probability:  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 79/79 [00:27<00:00,  2.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 4.09\n",
            "Test accuracy: 53.57%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "cBCrxbkxx3bw",
        "outputId": "0db60297-2f65-42a2-a803-d650fae32840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁</td></tr><tr><td>loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>53.57</td></tr><tr><td>loss</td><td>4.08987</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">heuristic_type_1</strong> at: <a href='https://wandb.ai/mali_team/RQ3/runs/eyhnpgxs' target=\"_blank\">https://wandb.ai/mali_team/RQ3/runs/eyhnpgxs</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230522_105722-eyhnpgxs/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}